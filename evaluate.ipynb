{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from components.data_synthesis import prep_metadata, prep_bin_data\n",
    "from components.synth_evaluator import SynthEvaluator\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "attack_size = 10 \n",
    "select_columns = {\n",
    "    'adults': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'],\n",
    "}\n",
    "#synthesis method\n",
    "synth_type = ['ctgan', 'dpctgan'] # 0,1\n",
    "sample_size = [0.25, 1, 2] # 0,1,2\n",
    "\n",
    "test_cases_1 = []\n",
    "for a in range (0,2):\n",
    "    scenario = {'dataset': 'adults'}\n",
    "    if a == 0:\n",
    "        scenario['columns_all'] = False\n",
    "        scenario['columns'] = select_columns['adults']\n",
    "    else:\n",
    "        scenario['columns_all'] = True\n",
    "        scenario['columns'] = []\n",
    "    for b in synth_type:\n",
    "        scenario['synth_type'] = b\n",
    "        for c in sample_size:\n",
    "            scenario['sample_size'] = c\n",
    "            test_cases_1.append({\n",
    "                'dataset': scenario['dataset'],\n",
    "                'columns_all': scenario['columns_all'], \n",
    "                'columns': scenario['columns'], \n",
    "                'synth_type': scenario['synth_type'],\n",
    "                'sample_size': scenario['sample_size']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_some_9758\n",
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_some_39032\n",
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_some_78064\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_some_9758\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_some_39032\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_some_78064\n",
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_all_9758\n",
      "fnlwgt  could not calculate ROCAUC due to single class in y_true\n",
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_all_39032\n",
      "fnlwgt  could not calculate ROCAUC due to single class in y_true\n",
      "\n",
      "==========\n",
      " 1_0_adults_ctgan_all_78064\n",
      "fnlwgt  could not calculate ROCAUC due to single class in y_true\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_all_9758\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_all_39032\n",
      "\n",
      "==========\n",
      " 1_0_adults_dpctgan_all_78064\n"
     ]
    }
   ],
   "source": [
    "#copy code from attack.ipynb to retreive data\n",
    "test_set_num = 1\n",
    "iterations = range(0,1)\n",
    "\n",
    "#these are the sheets we are capturing data:\n",
    "#these columns should be in them all\n",
    "# suffix, iteration, dataset, synth type, columns, synth size\n",
    "# row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size)]\n",
    "#attack accuracy scores: rate1, errorbound, rate2\n",
    "#defense scores: select columns + domias defense scores\n",
    "#utility scores: select columns coverage + mds scores\n",
    "\n",
    "book = xlsxwriter.Workbook('evaluation.xlsx')\n",
    "sheet1 = book.add_worksheet(\"accuracy\")\n",
    "sheet1.write_row(0, 0, ['suffix', 'iteration', 'dataset', 'synth type', 'columns', 'synth size', 'col type', 'rate1', 'error1', 'rate2'])\n",
    "sheet2 = book.add_worksheet(\"defense\")\n",
    "sheet2.write_row(0, 0, ['suffix', 'iteration', 'dataset', 'synth type', 'columns', 'synth size', 'col type', 'defense score'])\n",
    "sheet3 = book.add_worksheet(\"utility\")\n",
    "sheet3.write_row(0, 0, ['suffix', 'iteration', 'dataset', 'synth type', 'columns', 'synth size', 'col type', 'coverage', 'mds', 'wasKSTest'])\n",
    "\n",
    "row_count_sheet1 = 1\n",
    "row_count_sheet2 = 1\n",
    "row_count_sheet3 = 1\n",
    "\n",
    "for i in iterations:\n",
    "    for test_case in test_cases_1:\n",
    "        train_df = pd.read_parquet('dataset/' + test_case['dataset'] + '_train.parquet')\n",
    "        if not test_case['columns_all']:\n",
    "            train_df = train_df[test_case['columns']]\n",
    "        # account for all columns vs some columns\n",
    "        if not test_case['columns_all']:\n",
    "            train_df = train_df[test_case['columns']]\n",
    "\n",
    "        # account for bin sizing\n",
    "        bin_size = 50 # assume this bin size is sufficent in all cases and pandas bins efficientally\n",
    "        bin_columns = []\n",
    "        if test_case['columns_all'] and test_case['dataset'] == 'adults':\n",
    "            bin_columns = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hr_per_week']\n",
    "        elif (not test_case['columns_all']) and test_case['dataset'] == 'adults':\n",
    "            bin_columns = ['age']\n",
    "        if test_case['dataset'] != 'census1990':     \n",
    "            train_df = prep_bin_data(train_df, bin_columns, bin_size)\n",
    "\n",
    "        dataset_size = train_df.shape[0]\n",
    "        size = (int)(dataset_size * test_case['sample_size'])\n",
    "        columns_all_string = (\"all\" if test_case[\"columns_all\"] else \"some\")\n",
    "        file_suffix = str(test_set_num) + \"_\" + str(i) + \"_\" +\\\n",
    "            test_case['dataset'] + \"_\" +\\\n",
    "            test_case['synth_type'] + \"_\" +\\\n",
    "            columns_all_string + \"_\" +\\\n",
    "            str(size)\n",
    "        print(\"\\n==========\\n\", file_suffix)\n",
    "\n",
    "        if not os.path.isfile('dataset/results/attack_' + str(attack_size) + '_testset' + file_suffix + '.pkl'):\n",
    "            print(\"No Attack Result Available. Skipping... \\n\")\n",
    "            continue\n",
    "\n",
    "        metadata = prep_metadata(train_df)\n",
    "        metadata_dict = metadata.to_dict()\n",
    "\n",
    "        results = {}\n",
    "        #load attack results\n",
    "        with open('dataset/results/attack_' + str(attack_size) + '_testset' + file_suffix + '.pkl', 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "\n",
    "        #Evaluation\n",
    "        synthevaluator = SynthEvaluator(metadata)\n",
    "        defense_evaluation = synthevaluator.run_defense(results)\n",
    "        \n",
    "        # print(\"\\n\", defense_evaluation['accuracy'])\n",
    "        for col in select_columns['adults']:\n",
    "            accuracy_row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size),\n",
    "                col, defense_evaluation['accuracy']['anon_inference'][col]['rate1'], \n",
    "                defense_evaluation['accuracy']['anon_inference'][col]['error1'], \n",
    "                defense_evaluation['accuracy']['anon_inference'][col]['rate2']]\n",
    "            # print(accuracy_row_data)\n",
    "            sheet1.write_row(row_count_sheet1, 0, accuracy_row_data)\n",
    "            row_count_sheet1 = row_count_sheet1 + 1\n",
    "        accuracy_row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size),\n",
    "                'domias', defense_evaluation['accuracy']['domias']['rate1'], \n",
    "                defense_evaluation['accuracy']['domias']['error1'], \n",
    "                defense_evaluation['accuracy']['domias']['rate2']]\n",
    "        # print(accuracy_row_data) \n",
    "        sheet1.write_row(row_count_sheet1, 0, accuracy_row_data)\n",
    "        row_count_sheet1 = row_count_sheet1 + 1\n",
    "        \n",
    "        # print(\"\\n\", defense_evaluation['pairwise_error'])\n",
    "        \n",
    "        # print(\"\\n\", defense_evaluation['gda_defense'])\n",
    "        for col in select_columns['adults']:\n",
    "            gdadefense_row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size),\n",
    "                col, defense_evaluation['gda_defense']['anon_inference'][col]]\n",
    "            # print(gdadefense_row_data)\n",
    "            sheet2.write_row(row_count_sheet2, 0, gdadefense_row_data)\n",
    "            row_count_sheet2 = row_count_sheet2 + 1\n",
    "        gdadefense_row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size),\n",
    "                'domias', defense_evaluation['gda_defense']['domias']]\n",
    "        # print(gdadefense_row_data)\n",
    "        sheet2.write_row(row_count_sheet2, 0, gdadefense_row_data)\n",
    "        row_count_sheet2 = row_count_sheet2 + 1\n",
    "\n",
    "        synth_df = pd.read_parquet('dataset/synthetic/testset' + file_suffix + '.parquet')\n",
    "        utility_evaluation = synthevaluator.run_utility(train_df, synth_df)\n",
    "        \n",
    "        for col in select_columns['adults']:\n",
    "            utility_row_data = [file_suffix, i, test_case['dataset'], test_case['synth_type'], columns_all_string, str(size),\n",
    "                col, str(round(utility_evaluation[col]['coverage'],2)), \n",
    "                str(round(utility_evaluation[col]['mds']['mds'], 4)), \n",
    "                str(utility_evaluation[col]['mds']['kstest'])]\n",
    "            # print(utility_row_data)\n",
    "            sheet3.write_row(row_count_sheet3, 0, utility_row_data)\n",
    "            row_count_sheet3 = row_count_sheet3 + 1\n",
    "book.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
