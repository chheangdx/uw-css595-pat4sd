{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cases for Test Set 1\n",
      "==========\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'ctgan', 'sample_size': 0.25}\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'ctgan', 'sample_size': 1}\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'ctgan', 'sample_size': 2}\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'dpctgan', 'sample_size': 0.25}\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'dpctgan', 'sample_size': 1}\n",
      "{'dataset': 'adults', 'columns_all': False, 'columns': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'], 'synth_type': 'dpctgan', 'sample_size': 2}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'ctgan', 'sample_size': 0.25}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'ctgan', 'sample_size': 1}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'ctgan', 'sample_size': 2}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'dpctgan', 'sample_size': 0.25}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'dpctgan', 'sample_size': 1}\n",
      "{'dataset': 'adults', 'columns_all': True, 'columns': [], 'synth_type': 'dpctgan', 'sample_size': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from components.data_synthesis import prep_metadata, prep_bin_data\n",
    "from components.privacy_attack import PrivacyAttack\n",
    "\n",
    "import pickle\n",
    "\n",
    "#Round Parameters\n",
    "# dataset\n",
    "# round number\n",
    "# synthetic type\n",
    "#attack sizes: 10%, 50%, 100%, default is 10%\n",
    "attack_size = 10#data selection\n",
    "datasets = ['adults','diabetes','census1990'] #0,1,2\n",
    "#columns cases #1, 0\n",
    "all_columns = True \n",
    "select_columns = {\n",
    "    'adults': ['age', 'education', 'marital', 'occupation', 'income', 'race', 'sex'],\n",
    "    'diabetes': ['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'Stroke', 'HeartDiseaseorAttack', 'HvyAlcoholConsump', 'AnyHealthcare', 'GenHlth', 'MentHlth', 'PhysHlth', 'Sex', 'Age'],\n",
    "    'census1990': ['dAge', 'iMartial', 'iOccup', 'iSex', 'iSchool', 'iMilitary', 'iIndustry', 'iImmigr', 'iCitizen']\n",
    "}\n",
    "#synthesis method\n",
    "synth_type = ['ctgan', 'dpctgan'] # 0,1\n",
    "sample_size = [0.25, 1, 2] # 0,1,2\n",
    "# epochs = [0.1, 0.5, 1] # 0,1,2\n",
    "epochs = 0.1\n",
    "\n",
    "#first set of data: \n",
    "# Adults, CTGAN vs DPCTGAN, \n",
    "# All Columns vs Select Columns, \n",
    "# Various Sample Size and Attack Size\n",
    "\n",
    "test_cases_1 = []\n",
    "for a in range (0,2):\n",
    "    scenario = {'dataset': 'adults'}\n",
    "    if a == 0:\n",
    "        scenario['columns_all'] = False\n",
    "        scenario['columns'] = select_columns['adults']\n",
    "    else:\n",
    "        scenario['columns_all'] = True\n",
    "        scenario['columns'] = []\n",
    "    for b in synth_type:\n",
    "        scenario['synth_type'] = b\n",
    "        for c in sample_size:\n",
    "            scenario['sample_size'] = c\n",
    "            test_cases_1.append({\n",
    "                'dataset': scenario['dataset'],\n",
    "                'columns_all': scenario['columns_all'], \n",
    "                'columns': scenario['columns'], \n",
    "                'synth_type': scenario['synth_type'],\n",
    "                'sample_size': scenario['sample_size']\n",
    "            })\n",
    "\n",
    "print(\"Test Cases for Test Set 1\\n==========\")\n",
    "for test_case in test_cases_1:\n",
    "    print(test_case)\n",
    "\n",
    "#second set of data: \n",
    "# Adults vs US Census vs Diabetes, \n",
    "# CTGAN vs DPCTGAN, \n",
    "# All Columns, \n",
    "# 100% Sample Size and Attack Size\n",
    "\n",
    "test_cases_2 = []\n",
    "for a in datasets:\n",
    "    scenario = {}\n",
    "    scenario = {'dataset': a}\n",
    "    for b in synth_type:\n",
    "        scenario['synth_type'] = b\n",
    "        test_cases_2.append({\n",
    "            'dataset': scenario['dataset'],\n",
    "            'columns_all': True, \n",
    "            'columns': [], \n",
    "            'synth_type': scenario['synth_type'],\n",
    "            'sample_size': 1\n",
    "        }) \n",
    "\n",
    "test_case_test = [\n",
    "    {\n",
    "        'dataset': 'diabetes',\n",
    "        'columns_all': True, \n",
    "        'columns': [], \n",
    "        'synth_type': 'ctgan',\n",
    "        'sample_size': 1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "2_0_diabetes_ctgan_all_202944\n",
      "Running Domias Attack\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manon_inf_attacks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(synth_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mattack_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     49\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomias_synthetic_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(synth_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mattack_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprivacyattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_attack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynth_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msynth_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontrol_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspaces/CSS595-MastersProject/uw-css595-pat4sd/components/privacy_attack.py:103\u001b[0m, in \u001b[0;36mPrivacyAttack.inference_attack\u001b[0;34m(self, params, original_data, synth_data, control_data)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference_attack\u001b[39m(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     86\u001b[0m     params: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# run domias attack\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Domias Attack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m     domias_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_domias_overfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynth_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msynth_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontrol_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontrol_data\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     domias_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_domias_perf_to_results(\n\u001b[1;32m    110\u001b[0m         perf \u001b[38;5;241m=\u001b[39m domias_perf,\n\u001b[1;32m    111\u001b[0m         params \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# combine results and return\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspaces/CSS595-MastersProject/uw-css595-pat4sd/components/privacy_attack.py:203\u001b[0m, in \u001b[0;36mPrivacyAttack._domias_overfit\u001b[0;34m(self, params, original_data, synth_data, control_data)\u001b[0m\n\u001b[1;32m    201\u001b[0m         cat_columns\u001b[38;5;241m.\u001b[39mappend(column)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(cat_columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 203\u001b[0m     transformed_dfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_categories_to_num\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets_to_convert\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43moriginal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynth_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_columns\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m original_df\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m synth_df\n",
      "File \u001b[0;32m~/Workspaces/CSS595-MastersProject/uw-css595-pat4sd/components/privacy_attack.py:270\u001b[0m, in \u001b[0;36mPrivacyAttack._categories_to_num\u001b[0;34m(self, datasets_to_convert, columns)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m transformed_dfs:\n\u001b[0;32m--> 270\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m, col] \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# need to make sure everything is numeric\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m transformed_dfs:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:6112\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6108\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6110\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m-> 6112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:6222\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   6220\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   6221\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 6222\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   6223\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   6225\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   6226\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/construction.py:625\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    621\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m subarr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;66;03m# we will try to copy by-definition here\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/construction.py:814\u001b[0m, in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_cast_to_integer_array(arr, dtype)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m(arr, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subarr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_set = test_case_test\n",
    "test_set_num = 2\n",
    "iterations = range(0,1)\n",
    "\n",
    "for i in iterations:\n",
    "    print(\"Round: \", i)\n",
    "    # test_case = test_cases_1[0] #testing with 1 for now\n",
    "    for test_case in test_set:\n",
    "        train_df = pd.read_parquet('dataset/' + test_case['dataset'] + '_train.parquet')\n",
    "        control_df = pd.read_parquet('dataset/' + test_case['dataset'] + '_control.parquet')\n",
    "        \n",
    "        # account for all columns vs some columns\n",
    "        if not test_case['columns_all']:\n",
    "            train_df = train_df[test_case['columns']]\n",
    "            control_df = control_df[test_case['columns']]\n",
    "\n",
    "        # account for bin sizing\n",
    "        bin_size = 50 # assume this bin size is sufficent in all cases and pandas bins efficientally\n",
    "        bin_columns = []\n",
    "        if test_case['columns_all'] and test_case['dataset'] == 'adults':\n",
    "            bin_columns = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hr_per_week']\n",
    "        elif (not test_case['columns_all']) and test_case['dataset'] == 'adults':\n",
    "            bin_columns = ['age']\n",
    "        elif test_case['columns_all'] and test_case['dataset'] == 'diabetes':\n",
    "            bin_columns = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "        elif (not test_case['columns_all']) and test_case['dataset'] == 'diabetes':\n",
    "            bin_columns = ['GenHlth', 'MentHlth', 'PhysHlth', 'Age']\n",
    "        # census data is all categorical so no binning needed\n",
    "        if test_case['dataset'] != 'census1990':     \n",
    "            train_df = prep_bin_data(train_df, bin_columns, bin_size)\n",
    "            control_df = prep_bin_data(control_df, bin_columns, bin_size)\n",
    "        \n",
    "        dataset_size = train_df.shape[0]\n",
    "        size = (int)(dataset_size * test_case['sample_size'])\n",
    "        file_suffix = str(test_set_num) + \"_\" + str(i) + \"_\" +\\\n",
    "            test_case['dataset'] + \"_\" +\\\n",
    "            test_case['synth_type'] + \"_\" +\\\n",
    "            (\"all\" if test_case[\"columns_all\"] else \"some\")  + \"_\" +\\\n",
    "            str(size)\n",
    "        print(file_suffix)\n",
    "        synth_df = pd.read_parquet('dataset/synthetic/testset' + file_suffix + '.parquet')\n",
    "        metadata = prep_metadata(train_df)\n",
    "        # Attack\n",
    "        privacyattack = PrivacyAttack(metadata)\n",
    "        params = privacyattack.get_default_params()\n",
    "        params['domias_mem_set_size'] = train_df.shape[0]\n",
    "        params['domias_reference_set_size'] = control_df.shape[0]\n",
    "        params['anon_inf_attacks'] = int(synth_df.shape[0]*attack_size/100)\n",
    "        params['domias_synthetic_sizes'] = int(synth_df.shape[0]*attack_size/100)\n",
    "        results = privacyattack.inference_attack(\n",
    "            params = params,\n",
    "            original_data = train_df,\n",
    "            synth_data = synth_df,\n",
    "            control_data = control_df,    \n",
    "        )\n",
    "        #save results\n",
    "        # with open('dataset/results/attack_' + str(attack_size) + '_testset' + file_suffix + '.pkl', 'wb+') as f:\n",
    "        #     pickle.dump(results, f)\n",
    "        #     f.close()\n",
    "        # del train_df\n",
    "        # del control_df\n",
    "        # del synth_df\n",
    "        # del results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
